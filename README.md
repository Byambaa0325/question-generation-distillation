# Topic-Controllable Question Generation

Reproduction and extension of **"Topic-Controllable Question Generation"** — fine-tuning T5-small to generate questions conditioned on a Wikipedia topic concept, evaluated on SQuAD and KhanQ.

The repo also contains a **knowledge-distillation** branch that uses LLM teachers (Gemini, Ollama) to generate training data for a student model.

---

## Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Configuration](#configuration)
- [Quick Start — Pipeline API](#quick-start--pipeline-api)
- [Quick Start — CLI](#quick-start--cli)
- [Pipeline Stages](#pipeline-stages)
- [Training & Evaluation Results](#training--evaluation-results)
- [Backwards-Compatible Scripts](#backwards-compatible-scripts)
- [Knowledge Distillation](#knowledge-distillation)
- [Google Colab](#google-colab)

---

## Overview

The topic-QG pipeline has seven sequential stages:

```
Raw JSON  →  Convert  →  Wikify  →  Topics  →  Dataset  →  Train  →  Evaluate
                                                                  ↓
                                                              Generate
```

| Stage | What it does |
|-------|-------------|
| **Convert** | SQuAD / KhanQ JSON → flat `{id, text}` lists |
| **Wikify** | Annotate each text and question with Wikipedia entities (Wikifier.org or WAT) |
| **Topics** | Find the intersection concept between question and passage; pick highest-scoring |
| **Dataset** | Build `baseline` / `MixSQuAD` / `MixSQuAD2X` / `MixKhanQ` train/val/test CSVs |
| **Train** | Fine-tune T5-small with HuggingFace Trainer (paper format: `<topic> … <context> …`) |
| **Evaluate** | BLEU-1/2/3/4, F1, METEOR, ROUGE-L across all model variants |
| **Generate** | Beam-search inference (10 beams, 8 sequences) with sentence-embedding reranking |

---

## Project Structure

```
.
├── pipeline.py                  ← CLI entry point (all stages)
├── config/
│   ├── pipeline.yaml            ← Paths + hyperparameters (edit this)
│   ├── config.yaml              ← Distillation config
│   ├── settings.py              ← Distillation config loader
│   └── wikifier_config.json     ← Wikifier API key (legacy)
├── src/
│   ├── wikification/            ← NEW: unified wikification module
│   │   ├── base.py              BaseWikifier ABC (chunking, batch, resume)
│   │   ├── wikifier.py          Wikifier.org client (sorted by pageRank)
│   │   └── wat.py               WAT client (sorted by rho) + relatedness()
│   ├── pipeline/                ← NEW: importable pipeline
│   │   ├── config.py            PipelineConfig (loads pipeline.yaml)
│   │   ├── __init__.py          Pipeline class
│   │   └── stages/
│   │       ├── convert.py       Stage 1
│   │       ├── wikify.py        Stage 2
│   │       ├── topics.py        Stage 3
│   │       ├── dataset.py       Stage 4
│   │       ├── train.py         Stage 5 (HF Seq2SeqTrainer)
│   │       ├── evaluate.py      Stage 6
│   │       └── generate.py      Stage 7
│   ├── models/                  ← Distillation: teacher & student models
│   ├── distillation/            ← Distillation: trainer & losses
│   ├── generation/              ← Distillation: prompt templates
│   ├── evaluation/              ← Shared metrics (ROUGE, BLEU, BERTScore)
│   └── knowledge_graph/         ← ReAct-agent KG construction
├── scripts/                     ← Standalone scripts (backwards-compatible)
│   ├── convert_squad.py
│   ├── convert_khanq.py
│   ├── wikify_texts.py          ← now wraps src.wikification.Wikifier
│   ├── wikify_questions.py      ← now wraps src.wikification.Wikifier
│   ├── wikify_texts_incremental.py
│   ├── wikify_questions_incremental.py
│   ├── wikify_texts_wat.py
│   ├── wikify_wat_incremental.py
│   ├── select_topics_paper.py
│   ├── create_training_dataset.py
│   ├── train_t5.py              (PyTorch Lightning — legacy)
│   ├── train_t5_small.py        (custom loop — legacy)
│   ├── generate_questions.py
│   ├── evaluate_full_metrics.py
│   └── ...
├── data/
│   ├── raw/                     ← train-v1.1.json, KhanQ.json
│   └── processed/               ← generated by pipeline
├── models/                      ← saved T5 checkpoints
├── results/                     ← timestamped evaluation outputs
└── notebooks/                   ← Jupyter notebooks
```

---

## Installation

```bash
# Clone and install (editable, so src/ and scripts/ are importable)
pip install -e .

# Or install dependencies only
pip install -r requirements.txt
```

**Python ≥ 3.10** is required (uses `str | Path` union syntax).

---

## Configuration

### 1. API keys

Copy `.env.example` to `.env` and fill in your keys:

```bash
cp .env.example .env
```

| Variable | Used for |
|----------|----------|
| `WIKIFIER_API_KEY` | Wikifier.org annotation (Stage 2, default tool) |
| `WAT_TOKEN` | WAT / TagMe annotation (Stage 2, alternative) |
| `GOOGLE_API_KEY` / `GOOGLE_CLOUD_PROJECT` | Gemini teacher or evaluation |

> The Wikifier key is also stored in `config/wikifier_config.json` for legacy scripts.

### 2. Pipeline settings

Edit `config/pipeline.yaml` to change paths or hyperparameters:

```yaml
paths:
  raw:       data/raw
  processed: data/processed
  training:  data/training
  models:    models
  results:   results

wikification:
  tool:    wikifier   # wikifier | wat
  top_n:   5
  chunk_size: 650

training:
  model_name: google-t5/t5-small
  batch:      64
  lr:         1.0e-3
  epochs:     50
```

---

## Quick Start — Pipeline API

```python
from src.pipeline import Pipeline

pipe = Pipeline('config/pipeline.yaml')

# Run individual stages
pipe.convert(dataset='squad')
pipe.wikify(dataset='squad', tool='wikifier')
pipe.topics(dataset='squad')
pipe.dataset(dataset='squad', mode='mixsquad')
pipe.train(mode='topic')
results = pipe.evaluate(models='all', dataset='squad')

# Or run the full pipeline in one call
pipe.run(dataset='squad')

# Check which outputs already exist
pipe.status()

# Generate a single question
q = pipe.generate(
    topic='Photosynthesis',
    context='Plants convert light energy into chemical energy through ...',
)
print(q)
```

Every stage is **idempotent** — if output files already exist it prints `[SKIP]` and returns immediately.

---

## Quick Start — CLI

```bash
# Check progress
python pipeline.py status

# Stage by stage
python pipeline.py convert  --dataset squad
python pipeline.py wikify   --dataset squad --tool wikifier
python pipeline.py topics   --dataset squad
python pipeline.py dataset  --dataset squad --mode mixsquad
python pipeline.py train    --mode topic
python pipeline.py evaluate

# Generate one question
python pipeline.py generate \
    --topic "Photosynthesis" \
    --context "Plants convert sunlight into glucose..."

# Full pipeline end-to-end
python pipeline.py run --dataset squad

# Skip stages you've already run
python pipeline.py run --dataset squad --skip wikify topics
```

---

## Pipeline Stages

### Stage 1 — Convert

Converts raw JSON into the flat `{id, text}` format expected by wikification.

| Input | Output |
|-------|--------|
| `data/raw/train-v1.1.json` | `data/processed/ready_squad_text.json` |
| | `data/processed/ready_squad_question.json` |
| `data/raw/KhanQ.json` | `data/processed/ready_khanq_text.json` |
| | `data/processed/ready_khanq_question.json` |

### Stage 2 — Wikify

Calls the Wikifier.org or WAT API to annotate every text passage and question with Wikipedia entity concepts. Long passages are automatically chunked (≤ 650 chars). Saves progress every 50 items and resumes from where it left off if interrupted.

```bash
# Use WAT instead of the default Wikifier
python pipeline.py wikify --dataset squad --tool wat

# Only annotate texts (skip questions)
python pipeline.py wikify --dataset squad --target texts
```

### Stage 3 — Topics

Implements the paper's methodology: finds Wikipedia concepts that appear in **both** the question and the passage; selects the one with the highest `pageRank` (Wikifier) or `rho` (WAT). Entries with no overlapping concept receive topic `"NA"` and are filtered into a separate `_filtered.json` file used for training.

### Stage 4 — Dataset

Builds four dataset variants:

| Mode | Description | Size |
|------|-------------|------|
| `baseline` | Plain context, no mixing | ~87k after token filtering |
| `mixsquad` | Randomly paired, concatenated contexts | 10,000 |
| `mixsquad2x` | MixSQuAD doubled by reversing context order | ~20,000 |
| `mixkhanq` | KhanQ mixed pairs (evaluation, no train/val split) | 653 |

```bash
python pipeline.py dataset --dataset squad --mode mixsquad2x
python pipeline.py dataset --dataset khanq --mode mixkhanq
```

### Stage 5 — Train

Fine-tunes `google-t5/t5-small` using HuggingFace `Seq2SeqTrainer`.

**T5 format (paper standard):**

| | Value |
|-|-------|
| Input | `<topic> {topic} <context> {text} ` |
| Target | `{question}` |
| Special tokens | `<sep>`, `<space>` |
| Best checkpoint | saved at `models/{mode}/best_model/` (lowest val loss) |

```bash
python pipeline.py train --mode topic      # MixSQuAD
python pipeline.py train --mode topic2x    # MixSQuAD2X
python pipeline.py train --mode baseline
```

### Stage 6 — Evaluate

Evaluates all model variants on test data. Saves a timestamped results folder.

**Metrics:** BLEU-1/2/3/4 (word-level), token F1, METEOR, ROUGE-L.

**Model types supported:**
- `t5:baseline`, `t5:topic`, `t5:topic2x` — your fine-tuned models
- `ollama:<model_name>` — local Ollama zero-shot baseline
- `gemini:<model_name>` — Gemini zero-shot baseline

```bash
# All available T5 models
python pipeline.py evaluate

# Specific models
python pipeline.py evaluate --models "t5:topic,ollama:llama3.1:8b"
```

### Stage 7 — Generate

Generates a question for a single topic + context pair using beam search (10 beams, 8 candidate sequences) and sentence-transformer reranking.

```bash
python pipeline.py generate \
    --topic "Natural selection" \
    --context "Darwin proposed that organisms with favourable traits ..."
```

---

## Training & Evaluation Results

Paper baseline (SQuAD, character-level BLEU as reported):

| Model | BLEU-1 | BLEU-2 | BLEU-3 | BLEU-4 | F1 | METEOR | ROUGE-L |
|-------|--------|--------|--------|--------|----|--------|---------|
| T5-small baseline | 0.519 | 0.316 | 0.216 | 0.175 | 0.319 | 0.216 | 0.207 |
| T5-small + topic (MixSQuAD) | — | — | — | — | — | — | — |

> Word-level BLEU scores will differ from the paper's reported figures (the paper's evaluation code used character-level tokenisation). This implementation computes both; see `evaluate_full_metrics.py`.

---

## Backwards-Compatible Scripts

All original standalone scripts still work unchanged. The four Wikifier scripts now delegate to `src.wikification.Wikifier` but accept the same CLI arguments:

```bash
python scripts/wikify_texts.py \
    data/processed/ready_squad_text.json \
    data/processed/wikified_squad_text.json \
    $WIKIFIER_API_KEY

python scripts/wikify_questions_incremental.py \
    data/processed/ready_squad_question.json \
    data/processed/wikified_squad_question.json \
    $WIKIFIER_API_KEY

python scripts/select_topics_paper.py \
    data/processed/wikifier/wikified_squad_question.json \
    data/processed/wikifier/wikified_squad_text.json \
    data/processed/wikifier/enriched_squad.json \
    --score-field pageRank --filter

python scripts/create_training_dataset.py \
    --input data/processed/wikifier/enriched_squad_filtered.json \
    --output-dir data/training/squad/mixsquad \
    --mix

python scripts/evaluate_full_metrics.py \
    --test-data data/training/squad/mixsquad/test.csv \
    --t5-model models/topic/best_model
```

---

## Knowledge Distillation

A separate sub-system uses LLM teachers to generate level-conditioned training data for a smaller student model.

```python
from src.models.teacher import get_teacher
from src.models.student import T5Student

# Generate training data
teacher = get_teacher("gemini", model_name="gemini-1.5-flash")
questions = teacher.generate_questions(concept="Osmosis", level="beginner")

# Train student
python scripts/train_student.py \
    --train-data data/generated/training_data.json \
    --output-dir outputs/distillation
```

See `docs/README.md` for full distillation documentation.

---

## Google Colab

For GPU training without a local setup, use the notebooks in `notebooks/`:

| Notebook | Purpose |
|----------|---------|
| `01_data_generation.ipynb` | Teacher data generation |
| `02_distillation_training.ipynb` | Student model training |
| `03_evaluation.ipynb` | Metric evaluation |
| `04_knowledge_graph.ipynb` | KG construction |

See `notebooks/README.md` for Colab-specific setup instructions and expected training times (T4: ~20 min/epoch, A100: ~5 min/epoch).

---

## Data Files Required

Place these files in `data/raw/` before running the pipeline:

| File | Source |
|------|--------|
| `train-v1.1.json` | [SQuAD 1.1](https://rajpurkar.github.io/SQuAD-explorer/) |
| `KhanQ.json` | KhanQ dataset (included in repo) |
