{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"},
  "colab": {"provenance": []}
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": "# T5 Question Generation — Colab Training\n\nStandalone notebook for training and evaluating T5 topic-controlled question generation on Google Colab.\n\n**Use this notebook when:**\n- You have already run the data pipeline locally (stages 1–4) and have the CSV files\n- You want to train on Colab's GPU and evaluate with the full metric suite\n\n**Steps:**\n1. Setup environment and clone repo\n2. Upload training CSVs from your local pipeline run\n3. Train one or more model variants with `pipe.train()`\n4. Evaluate with `pipe.evaluate()` against paper baselines\n5. Download the trained model\n\n**Expected CSV files** (produced by `01_data_generation.ipynb` or `pipeline.py dataset`):\n```\ndata/training/squad/baseline/  train.csv  val.csv  test.csv\ndata/training/squad/mixsquad/  train.csv  val.csv  test.csv\ndata/training/khanq/mixkhanq/  data.csv\n```"
  },
  {
   "cell_type": "markdown",
   "id": "md-setup",
   "metadata": {},
   "source": "## 1. Setup"
  },
  {
   "cell_type": "code",
   "id": "code-gpu",
   "metadata": {},
   "source": "# Check GPU\n!nvidia-smi\n\nimport torch\nprint(f\"\\nPyTorch : {torch.__version__}\")\nprint(f\"CUDA    : {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    name = torch.cuda.get_device_name(0)\n    mem  = torch.cuda.get_device_properties(0).total_memory / 1e9\n    print(f\"GPU     : {name} ({mem:.0f} GB)\")\n    # Suggest batch size based on available VRAM\n    suggested_batch = 128 if mem >= 35 else 64 if mem >= 15 else 32\n    print(f\"Suggested batch size: {suggested_batch}\")\nelse:\n    print(\"WARNING: No GPU detected. Training will be very slow.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "code-env",
   "metadata": {},
   "source": "import sys, os\nfrom pathlib import Path\n\n# ── Clone repository ──────────────────────────────────────────────────────────\n# TODO: replace with your actual repository URL\nREPO_URL = \"https://github.com/YOUR_ORG/YOUR_REPO.git\"\n!git clone {REPO_URL} /content/ai4ed-qg -q\n%cd /content/ai4ed-qg\n\n# ── Install dependencies ──────────────────────────────────────────────────────\n!pip install -q torch transformers datasets accelerate sentencepiece \\\n                evaluate rouge_score nltk sentence-transformers \\\n                pyyaml tqdm pandas python-dotenv\n\nimport nltk\nfor res in ('punkt', 'punkt_tab', 'wordnet', 'omw-1.4'):\n    nltk.download(res, quiet=True)\n\nsys.path.insert(0, '/content/ai4ed-qg')\nos.chdir('/content/ai4ed-qg')\nprint(f\"Working dir: {os.getcwd()}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "code-drive",
   "metadata": {},
   "source": "from google.colab import drive\ndrive.mount('/content/drive')\n\nDRIVE_DIR = Path('/content/drive/MyDrive/ai4ed_qg')\nDRIVE_DIR.mkdir(parents=True, exist_ok=True)\nprint(f\"Drive directory: {DRIVE_DIR}\")\n\n# Restore any previously saved models from Drive\nimport shutil\nfor subdir in ('models', 'results'):\n    src = DRIVE_DIR / subdir\n    dst = Path('/content/ai4ed-qg') / subdir\n    if src.exists():\n        shutil.copytree(src, dst, dirs_exist_ok=True)\n        print(f\"Restored {subdir}/ from Drive\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "md-data",
   "metadata": {},
   "source": "## 2. Upload Training Data\n\nUpload the CSV files produced by the data pipeline. You need at minimum:\n- `train.csv` + `val.csv` for the mode you want to train\n- `data.csv` (MixKhanQ) for evaluation\n\n**Option A**: Upload from your local machine using the cell below.\n**Option B**: Copy from Drive if you already uploaded them."
  },
  {
   "cell_type": "code",
   "id": "code-upload",
   "metadata": {},
   "source": "# ── Option A: upload from local machine ──────────────────────────────────────\n# Run this cell and select your CSV files.\n# Files will be placed in the correct data/training/ subdirectory.\n\nfrom google.colab import files\nimport shutil\n\nprint(\"Select CSV files to upload (train.csv, val.csv, test.csv, data.csv)...\")\nuploaded = files.upload()\n\nfor filename in uploaded:\n    print(f\"Uploaded: {filename}\")\n\n# After uploading, place files manually:\n# data/training/squad/mixsquad/train.csv  → for 'topic' mode\n# data/training/squad/baseline/train.csv  → for 'baseline' mode\n# data/training/khanq/mixkhanq/data.csv   → for evaluation",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "code-place-files",
   "metadata": {},
   "source": "# ── Place uploaded files into the correct directories ─────────────────────────\n# Edit this mapping to match what you uploaded.\n# Keys are uploaded filenames, values are destination paths.\n\nimport shutil\nfrom pathlib import Path\n\nfile_placement = {\n    # 'train.csv': 'data/training/squad/mixsquad/train.csv',\n    # 'val.csv':   'data/training/squad/mixsquad/val.csv',\n    # 'test.csv':  'data/training/squad/mixsquad/test.csv',\n    # 'data.csv':  'data/training/khanq/mixkhanq/data.csv',\n}\n\nfor src_name, dst_rel in file_placement.items():\n    src = Path(src_name)\n    dst = Path(dst_rel)\n    if src.exists():\n        dst.parent.mkdir(parents=True, exist_ok=True)\n        shutil.copy(src, dst)\n        print(f\"Placed: {src_name} → {dst}\")\n    else:\n        print(f\"Not found: {src_name}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "code-verify-data",
   "metadata": {},
   "source": "# ── Option B: copy from Drive ─────────────────────────────────────────────────\n# If you already have data on Drive, copy it here:\nimport shutil\nfor subdir in ('processed', 'training'):\n    src = DRIVE_DIR / subdir\n    dst = Path('/content/ai4ed-qg/data') / subdir\n    if src.exists():\n        shutil.copytree(src, dst, dirs_exist_ok=True)\n        print(f\"Restored data/{subdir}/ from Drive\")\n    else:\n        print(f\"Not found in Drive: {subdir}/\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "md-init",
   "metadata": {},
   "source": "## 3. Initialise Pipeline"
  },
  {
   "cell_type": "code",
   "id": "code-init",
   "metadata": {},
   "source": "from src.pipeline import Pipeline\n\npipe = Pipeline('config/pipeline.yaml')\npipe.status()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "code-config",
   "metadata": {},
   "source": "# ── Tweak training config for your GPU ───────────────────────────────────────\n# Edit pipeline.yaml to make changes permanent, or override here:\n\npipe.config.training.batch  = 64     # 128 for A100, 64 for T4/V100, 32 if OOM\npipe.config.training.epochs = 50     # paper uses 50\npipe.config.training.lr     = 1e-3\n\nt = pipe.config.training\nprint(f\"Model      : {t.model_name}\")\nprint(f\"Batch size : {t.batch}\")\nprint(f\"Epochs     : {t.epochs}\")\nprint(f\"LR         : {t.lr}\")\nprint(f\"Max input  : {t.max_input_len} tokens\")\nprint(f\"Max output : {t.max_output_len} tokens\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "md-train",
   "metadata": {},
   "source": "## 4. Train\n\nTrain the model variant you need. The pipeline uses the correct paper format for all modes:\n```\nInput:  <topic> {topic} <context> {combined text}\nTarget: {question}\n```\n\nSaved to `models/{mode}/best_model/` (best checkpoint by validation loss)."
  },
  {
   "cell_type": "code",
   "id": "code-train-topic",
   "metadata": {},
   "source": "# ── TopicQG — trained on MixSQuAD (10k mixed pairs) ─────────────────────────\nmodel_path = pipe.train(mode='topic', dataset='squad')\nprint(f\"\\nModel saved to: {model_path}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "code-train-baseline",
   "metadata": {},
   "source": "# ── Baseline — context only, no topic signal ─────────────────────────────────\n# model_path = pipe.train(mode='baseline', dataset='squad')\n# print(f\"Model saved to: {model_path}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "code-train-topic2x",
   "metadata": {},
   "source": "# ── TopicQG2X — trained on MixSQuAD2X (20k, reversed context order) ─────────\n# model_path = pipe.train(mode='topic2x', dataset='squad')\n# print(f\"Model saved to: {model_path}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "md-generate-test",
   "metadata": {},
   "source": "## 5. Quick Generation Test"
  },
  {
   "cell_type": "code",
   "id": "code-generate-test",
   "metadata": {},
   "source": "topic   = \"Electronegativity\"\ncontext = (\n    \"Electronegativity is a measure of the tendency of an atom to attract \"\n    \"a bonding pair of electrons. The Pauling scale is the most commonly \"\n    \"used. Fluorine has the highest electronegativity (4.0). \"\n    \"Electronegativity increases across a period and decreases down a group.\"\n)\n\nquestion = pipe.generate(topic=topic, context=context, mode='topic')\nprint(f\"Topic   : {topic}\")\nprint(f\"Question: {question}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "md-evaluate",
   "metadata": {},
   "source": "## 6. Evaluate\n\nRuns the full metric suite (word-level BLEU, char-level BLEU, F1, METEOR, ROUGE-L, Perplexity) and prints a comparison table against paper baselines.\n\n**KhanQ evaluation** uses the `mixkhanq/data.csv` set (653 pairs, `topic2`/`question2` columns — paper's method)."
  },
  {
   "cell_type": "code",
   "id": "code-eval",
   "metadata": {},
   "source": "# Evaluate T5 models only (no Ollama/Gemini needed)\nresults = pipe.evaluate(\n    models='t5:topic',          # or 't5:baseline,t5:topic,t5:topic2x' or 'all'\n    dataset='khanq',\n)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "code-results",
   "metadata": {},
   "source": "import pandas as pd\n\nrows = []\nfor key, m in results.items():\n    rows.append({\n        'model':       key,\n        'n':           m.get('num_samples', '-'),\n        'B1 (word)':   round(m.get('bleu1',      0), 3),\n        'B4 (word)':   round(m.get('bleu4',      0), 3),\n        'B1c (paper)': round(m.get('bleu1_char', 0), 3),\n        'B4c (paper)': round(m.get('bleu4_char', 0), 3),\n        'F1':          round(m.get('f1',          0), 3),\n        'METEOR':      round(m.get('meteor',      0), 3),\n        'ROUGE-L':     round(m.get('rouge_l',     0), 3),\n        'PPL':         round(m.get('perplexity',  float('nan')), 3),\n    })\n\ndf = pd.DataFrame(rows).set_index('model')\npd.set_option('display.max_columns', None)\ndf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "md-paper-baselines",
   "metadata": {},
   "source": "### Paper Baselines (char-level BLEU, KhanQ)\n\n| Model | B1c | B2c | B3c | B4c | F1 | METEOR | ROUGE-L | PPL |\n|-------|-----|-----|-----|-----|----|--------|---------|-----|\n| Baseline | 0.519 | 0.316 | 0.216 | 0.175 | 0.319 | 0.216 | 0.207 | 1.303 |\n| TopicQGedu | 0.551 | 0.335 | 0.221 | 0.177 | 0.302 | 0.216 | 0.204 | 1.360 |\n| **TopicQG** | **0.551** | **0.343** | **0.236** | **0.191** | **0.330** | **0.233** | **0.230** | **1.323** |\n| TopicQG 8-bit | 0.546 | 0.339 | 0.231 | 0.186 | 0.319 | 0.226 | 0.225 | 1.327 |\n| TopicQG 4-bit | 0.543 | 0.337 | 0.231 | 0.186 | 0.318 | 0.223 | 0.223 | 1.334 |\n| TopicQG2X | 0.536 | 0.328 | 0.221 | 0.177 | 0.321 | 0.220 | 0.216 | 1.345 |\n\n> Use `B1c`/`B4c` columns from the results table above for direct comparison."
  },
  {
   "cell_type": "markdown",
   "id": "md-save",
   "metadata": {},
   "source": "## 7. Save to Drive"
  },
  {
   "cell_type": "code",
   "id": "code-save-drive",
   "metadata": {},
   "source": "import shutil\n\n# Sync models and results to Drive\nfor subdir in ('models', 'results'):\n    src = Path('/content/ai4ed-qg') / subdir\n    dst = DRIVE_DIR / subdir\n    if src.exists():\n        shutil.copytree(src, dst, dirs_exist_ok=True)\n        print(f\"Synced {subdir}/ to Drive\")\n\nprint(f\"\\nAll files saved to: {DRIVE_DIR}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "code-download",
   "metadata": {},
   "source": "# Download best model as zip\nimport shutil\nfrom google.colab import files as colab_files\n\nmodel_dir = Path('/content/ai4ed-qg/models/topic/best_model')\nif model_dir.exists():\n    shutil.make_archive('/content/t5_topic_best_model', 'zip', model_dir)\n    colab_files.download('/content/t5_topic_best_model.zip')\nelse:\n    print(\"Model not found — train first\")",
   "outputs": [],
   "execution_count": null
  }
 ]
}
